{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LV2HHrYADIgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gxXxmpgDGbS",
        "outputId": "8895ec94-06c3-4f0d-8e7c-2c9682e4c80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, concat_ws, expr, year, month\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================================================\n",
        "# Assignment: Airline Customer Data Analysis with PySpark\n",
        "# ==================================================\n",
        "\n",
        "# ----------------------------------------\n",
        "# 1. Extract Data to DataFrame\n",
        "# ----------------------------------------\n",
        "# 1.1 Setup SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"AirlineCustomerAnalysis\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# 1.2 Create output directories\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "for d in [\"output/results\", \"output/graphs\"]:\n",
        "    ensure_dir(d)\n",
        "\n",
        "# 1.3 Download datasets\n",
        "os.system(\n",
        "    \"wget -q https://raw.githubusercontent.com/RafliFa31/Assignment_21/main/calendar.csv -O calendar.csv\"\n",
        ")\n",
        "os.system(\n",
        "    \"wget -q https://raw.githubusercontent.com/RafliFa31/Assignment_21/main/customer_flight_activity.csv -O customer_flight_activity.csv\"\n",
        ")\n",
        "os.system(\n",
        "    \"wget -q https://raw.githubusercontent.com/RafliFa31/Assignment_21/main/customer_loyalty_history.csv -O customer_loyalty_history.csv\"\n",
        ")\n",
        "\n",
        "# 1.4 Read CSV into DataFrames\n",
        "df_calendar = spark.read.option(\"header\", True).csv(\"calendar.csv\", inferSchema=True)\n",
        "df_flights  = spark.read.option(\"header\", True).csv(\"customer_flight_activity.csv\", inferSchema=True)\n",
        "df_loyalty  = spark.read.option(\"header\", True).csv(\"customer_loyalty_history.csv\", inferSchema=True)\n",
        "\n",
        "# 1.5 Display schema for verification\n",
        "df_calendar.printSchema()\n",
        "df_flights.printSchema()\n",
        "df_loyalty.printSchema()\n",
        "\n",
        "# ----------------------------------------\n",
        "# 2. Data Cleaning\n",
        "# ----------------------------------------\n",
        "# 2.1 Remove duplicate records\n",
        "df_calendar = df_calendar.dropDuplicates()\n",
        "df_flights  = df_flights.dropDuplicates()\n",
        "df_loyalty  = df_loyalty.dropDuplicates()\n",
        "\n",
        "# 2.2 Handle missing values\n",
        "# Drop flights rows missing key identifiers, drop loyalty rows missing LoyaltyNumber\n",
        "df_flights = df_flights.dropna(subset=[\"loyalty_number\", \"year\", \"month\"])\n",
        "df_loyalty = df_loyalty.dropna(subset=[\"loyalty_number\"])\n",
        "\n",
        "# 2.3 Cast Year and Month to integer for consistency\n",
        "df_flights  = df_flights.withColumn(\"year\", col(\"year\").cast(\"int\")).withColumn(\"month\", col(\"month\").cast(\"int\"))\n",
        "\n",
        "# ----------------------------------------\n",
        "# 3. Data Transformation\n",
        "# ----------------------------------------\n",
        "# 3.1 Join customer flight activity with loyalty history\n",
        "joined = df_flights.join(df_loyalty, on=\"loyalty_number\", how=\"inner\")\n",
        "\n",
        "# 3.2 Compute NetPoints = PointsAccumulated - PointsRedeemed\n",
        "joined = joined.withColumn(\"NetPoints\", col(\"points_accumulated\") - col(\"points_redeemed\"))\n",
        "\n",
        "# 3.3 Enrich with calendar (add MonthName) - Removed as MonthName is not in calendar.csv\n",
        "# joined = joined.join(\n",
        "#     df_calendar.select(\"Year\", \"Month\", \"MonthName\"),\n",
        "#     on=[\"Year\", \"Month\"], how=\"left\"\n",
        "# )\n",
        "\n",
        "# 3.4 Create YearMonth column for time series analyses\n",
        "joined = joined.withColumn(\n",
        "    \"YearMonth\", concat_ws(\"-\", col(\"year\"), expr(\"lpad(month,2,'0')\"))\n",
        ")\n",
        "\n",
        "# 3.5 Register DataFrame as SQL view\n",
        "joined.createOrReplaceTempView(\"all_data\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# 4. Analysis with PySpark SQL\n",
        "# ----------------------------------------\n",
        "# 4.1 Average flights per customer per year\n",
        "avg_flights = spark.sql(\n",
        "    \"SELECT year, ROUND(AVG(`total_flights`),2) AS AvgFlightsPerCust \"\n",
        "    \"FROM all_data GROUP BY year ORDER BY year\"\n",
        ")\n",
        "\n",
        "# 4.2 Distribution of net points by loyalty card status\n",
        "points_by_card = spark.sql(\n",
        "    \"SELECT `loyalty_card` AS Card, ROUND(AVG(NetPoints),2) AS AvgNetPoints \"\n",
        "    \"FROM all_data GROUP BY `loyalty_card`\"\n",
        ")\n",
        "\n",
        "# 4.3 Relationship between education level and flights\n",
        "flights_by_edu = spark.sql(\n",
        "    \"SELECT education, ROUND(AVG(`total_flights`),2) AS AvgFlights \"\n",
        "    \"FROM all_data GROUP BY education\"\n",
        ")\n",
        "\n",
        "# 4.4 Trend of total flights over time (per month)\n",
        "trends = spark.sql(\n",
        "    \"SELECT YearMonth, SUM(`total_flights`) AS TotalFlights \"\n",
        "    \"FROM all_data GROUP BY YearMonth ORDER BY YearMonth\"\n",
        ")\n",
        "\n",
        "# 4.5 Export SQL results to CSV\n",
        "for df, fname in [\n",
        "    (avg_flights, \"avg_flights_per_year.csv\"),\n",
        "    (points_by_card, \"avg_points_by_card.csv\"),\n",
        "    (flights_by_edu, \"avg_flights_by_education.csv\"),\n",
        "    (trends, \"trend_flights_per_month.csv\")\n",
        "]:\n",
        "    df.coalesce(1).write.csv(f\"output/results/{fname}\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# 5. Visualization\n",
        "# ----------------------------------------\n",
        "# Convert Spark DataFrames to Pandas for plotting\n",
        "df_list = {\n",
        "    'avg_flights': avg_flights.toPandas(),\n",
        "    'points_by_card': points_by_card.toPandas(),\n",
        "    'flights_by_edu': flights_by_edu.toPandas(),\n",
        "    'trends': trends.toPandas()\n",
        "}\n",
        "\n",
        "# 5.1 Trend Total Flights per Month\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(df_list['trends']['YearMonth'], df_list['trends']['TotalFlights'], marker='o', label='Total Flights')\n",
        "plt.title('Trend Total Flights per Month')\n",
        "plt.xlabel('Year-Month')\n",
        "plt.ylabel('Total Flights')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/graphs/trend_flights_per_month.png')\n",
        "plt.close()\n",
        "\n",
        "# 5.2 Average Flights per Customer per Year\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(df_list['avg_flights']['year'].astype(str), df_list['avg_flights']['AvgFlightsPerCust'], label='Avg Flights')\n",
        "plt.title('Average Flights per Customer per Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Avg Flights per Customer')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/graphs/avg_flights_per_year.png')\n",
        "plt.close()\n",
        "\n",
        "# 5.3 Average Net Points by Loyalty Card Status\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(df_list['points_by_card']['Card'], df_list['points_by_card']['AvgNetPoints'], label='Avg Net Points')\n",
        "plt.title('Average Net Points by Loyalty Card Status')\n",
        "plt.xlabel('Loyalty Card')\n",
        "plt.ylabel('Avg Net Points')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/graphs/avg_points_by_card.png')\n",
        "plt.close()\n",
        "\n",
        "# 5.4 Average Flights by Education Level (extra)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(df_list['flights_by_edu']['education'], df_list['flights_by_edu']['AvgFlights'], label='Avg Flights')\n",
        "plt.title('Average Flights by Education Level')\n",
        "plt.xlabel('Education')\n",
        "plt.ylabel('Avg Flights')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/graphs/avg_flights_by_education.png')\n",
        "plt.close()\n",
        "\n",
        "# ----------------------------------------\n",
        "# 6. Save Full Dataset Outputs\n",
        "# ----------------------------------------\n",
        "# Save enriched full dataset for reference\n",
        "joined = joined.drop(\"_c0\") # Drop the extra column before saving\n",
        "joined.write.parquet(\"output/results/full_customer_data.parquet\", mode=\"overwrite\")\n",
        "joined.write.json(\"output/results/full_customer_data.json\", mode=\"overwrite\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# 7. Documentation Placeholder\n",
        "# ----------------------------------------\n",
        "# Dokumentasi langkah ETL, query SQL, dan insight dapat ditulis di README.md atau report.md\n",
        "# Contoh:\n",
        "# - 1. Extract Data: calendar.csv, ...\n",
        "# - 2. Clean: dropDuplicates, dropna\n",
        "# - 3. Transform: join, NetPoints, YearMonth\n",
        "# - 4. SQL Analysis: avg_flights, ...\n",
        "# - 5. Visual: trend_flights_per_month.png, ...\n",
        "# - 6. Save: CSV, Parquet, JSON\n",
        "\n",
        "print(\"ETL, SQL analysis, dan visualisasi selesai. Output di folder output/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLc9czdaDHqH",
        "outputId": "0fffcb96-e1e2-4bf3-fc4c-77e0ba03e078"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- start_of_the_year: date (nullable = true)\n",
            " |-- start_of_the_quarter: date (nullable = true)\n",
            " |-- start_of_the_month: date (nullable = true)\n",
            "\n",
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- loyalty_number: integer (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- total_flights: integer (nullable = true)\n",
            " |-- distance: integer (nullable = true)\n",
            " |-- points_accumulated: double (nullable = true)\n",
            " |-- points_redeemed: integer (nullable = true)\n",
            " |-- dollar_cost_points_redeemed: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- loyalty_number: integer (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- province: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            " |-- marital_status: string (nullable = true)\n",
            " |-- loyalty_card: string (nullable = true)\n",
            " |-- customer_lifetime_value: string (nullable = true)\n",
            " |-- enrollment_type: string (nullable = true)\n",
            " |-- enrollment_year: string (nullable = true)\n",
            " |-- enrollment_month: string (nullable = true)\n",
            " |-- cancellation_year: double (nullable = true)\n",
            " |-- cancellation_month: double (nullable = true)\n",
            "\n",
            "ETL, SQL analysis, dan visualisasi selesai. Output di folder output/\n"
          ]
        }
      ]
    }
  ]
}